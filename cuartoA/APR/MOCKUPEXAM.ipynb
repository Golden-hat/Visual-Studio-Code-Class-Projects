{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exámenes A1 y A3 de APR en el grupo 4CO11, turno 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Examen A1: ejercicio con Fashion-MNIST"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Los ejercicios de las sesiones de laboratorio del bloque 1 se han basado en el corpus Fashion-MNIST. Hemos utilizado el código siguiente para leer Fashion-MNIST con su partición train-test estándar, normalizar las imágenes a $\\,[0,1]\\,$, y establecer una partición train-val-test mediante partición del train estándar en train-val."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train (50000, 784) (50000, 10) val (10000, 784) (10000, 10) test (10000, 784) (10000, 10)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np; import matplotlib.pyplot as plt\n",
    "import os; os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'; import keras\n",
    "input_dim = 784; num_classes = 10\n",
    "(x_train_val, y_train_val), (x_test, y_test) = keras.datasets.fashion_mnist.load_data()\n",
    "x_train_val = x_train_val.reshape(-1, input_dim).astype(\"float32\") / 255.0\n",
    "x_test = x_test.reshape(-1, input_dim).astype(\"float32\") / 255.0\n",
    "y_train_val = keras.utils.to_categorical(y_train_val, num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)\n",
    "x_train = x_train_val[:-10000]; x_val = x_train_val[-10000:]\n",
    "y_train = y_train_val[:-10000]; y_val = y_train_val[-10000:]\n",
    "print(f'train {x_train.shape} {y_train.shape} val {x_val.shape} {y_val.shape} test {x_test.shape} {y_test.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La mejor precisión en test encontrada, $\\,89.6\\%,\\,$ se ha hallado con los siguientes hiperparámetros: arquitectura de MLP con una capa oculta de $\\,800\\,$ RELUs; optimizador Adam con learning rate $\\,0.00015\\,$ y batch size $\\,256;\\;$ planificador ReduceLROnPlateau con factor $\\,0.32\\,$ y paciencia $\\,5;\\;$ y regularización mediante early stopping con paciencia $\\,10.$ A continuación se define una función que, dados inicializadores de kernel y bias, realiza un experimento con dichos hiperparámetros y devuelve la precisión en test encontrada:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_exp(kernel_initializer=\"glorot_uniform\", bias_initializer=\"zeros\"):\n",
    "  M = keras.Sequential()\n",
    "  M.add(keras.Input(shape=(784,)))\n",
    "  M.add(keras.layers.Dense(units=800, activation='relu',\n",
    "    kernel_initializer=kernel_initializer, bias_initializer=bias_initializer))\n",
    "  M.add(keras.layers.Dense(10, activation='softmax',\n",
    "    kernel_initializer=kernel_initializer, bias_initializer=bias_initializer))\n",
    "  opt = keras.optimizers.Adam(learning_rate=0.00015)\n",
    "  M.compile(loss=\"categorical_crossentropy\", optimizer=opt, metrics=[\"accuracy\"])\n",
    "  reduce_cb = keras.callbacks.ReduceLROnPlateau(\n",
    "    monitor='val_accuracy', factor=0.32, patience=5, restore_best_weights=True)\n",
    "  early_cb = keras.callbacks.EarlyStopping(monitor='val_accuracy', patience=10, min_delta=1e-5)\n",
    "  M.fit(x_train, y_train, batch_size=256, epochs=100, verbose=0, validation_data=(x_val, y_val),\n",
    "    callbacks=[reduce_cb, early_cb])\n",
    "  _, acc = M.evaluate(x_test, y_test, verbose=0)\n",
    "  return acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Los inicializadores de kernel y bias por omisión, GlorotUniform y ceros, son los mismos que emplea keras por omisión. Dado que GlorotUniform es una inicialización aleatoria, cada vez que realicemos el experimento anterior obtendremos una precisión en test (ligeramente) distinta. Veamos la precisión en test que se obtiene en un experimento aislado con una semilla aleatoria $23$; debería ser próxima a $\\,89.6\\%,\\,$ si bien puede variar a causa del indeterminismo intrínseco del cálculo masivamente paralelo y, en general, de diferencias en el entorno de ejecución."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1733933806.457772   38295 gpu_device.cc:2022] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 2616 MB memory:  -> device: 0, name: NVIDIA GeForce GTX 1650, pci bus id: 0000:01:00.0, compute capability: 7.5\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1733933808.028319   39942 service.cc:148] XLA service 0x7fac580046e0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "I0000 00:00:1733933808.028353   39942 service.cc:156]   StreamExecutor device (0): NVIDIA GeForce GTX 1650, Compute Capability 7.5\n",
      "I0000 00:00:1733933808.127747   39942 cuda_dnn.cc:529] Loaded cuDNN version 90300\n",
      "I0000 00:00:1733933808.853674   39942 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precisión: 89.26%\n",
      "Tiempo (hh:mm:ss): 00:00:28\n"
     ]
    }
   ],
   "source": [
    "import time; start = time.time()\n",
    "keras.utils.set_random_seed(seed=23); acc = run_exp(); print(f'Precisión: {acc:.2%}')\n",
    "print('Tiempo (hh:mm:ss):', time.strftime('%H:%M:%S', time.gmtime(time.time() - start)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Conviene repetir el experimento varias veces para hallar una estimación fiable de la precisión en test que cabe esperar:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1733934655.719036  149332 service.cc:148] XLA service 0x7f82d80081c0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "I0000 00:00:1733934655.719060  149332 service.cc:156]   StreamExecutor device (0): NVIDIA GeForce GTX 1650, Compute Capability 7.5\n",
      "I0000 00:00:1733934655.811875  149332 cuda_dnn.cc:529] Loaded cuDNN version 90300\n",
      "I0000 00:00:1733934656.469199  149332 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precisión media: 89.52%  Desviación estándar: 0.09%\n",
      "Tiempo (hh:mm:ss): 00:04:54\n"
     ]
    }
   ],
   "source": [
    "import time; start = time.time()\n",
    "keras.utils.set_random_seed(seed=23); num_exp = 10; acc = np.zeros(num_exp)\n",
    "for exp in range(num_exp):\n",
    "    acc[exp] = run_exp()\n",
    "print(f'Precisión media: {acc.mean():.2%}  Desviación estándar: {acc.std():.2%}')\n",
    "print('Tiempo (hh:mm:ss):', time.strftime('%H:%M:%S', time.gmtime(time.time() - start)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Ejercicio (2 puntos):** $\\;$ escoge un inicializador de kernel aleatorio y distinto a GlorotUniform, y estima la precisión en test mediante repetición del experimento anterior dos veces al menos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train (50000, 784) (50000, 10) val (10000, 784) (10000, 10) test (10000, 784) (10000, 10)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np; import matplotlib.pyplot as plt\n",
    "import os; os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'; import keras\n",
    "input_dim = 784; num_classes = 10\n",
    "(x_train_val, y_train_val), (x_test, y_test) = keras.datasets.fashion_mnist.load_data()\n",
    "x_train_val = x_train_val.reshape(-1, input_dim).astype(\"float32\") / 255.0\n",
    "x_test = x_test.reshape(-1, input_dim).astype(\"float32\") / 255.0\n",
    "y_train_val = keras.utils.to_categorical(y_train_val, num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)\n",
    "x_train = x_train_val[:-10000]; x_val = x_train_val[-10000:]\n",
    "y_train = y_train_val[:-10000]; y_val = y_train_val[-10000:]\n",
    "print(f'train {x_train.shape} {y_train.shape} val {x_val.shape} {y_val.shape} test {x_test.shape} {y_test.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CAMBIAMOS glorot_uniform por otro kernel_initializer aleatorio, por e\n",
    "def run_exp(kernel_initializer=\"random_normal\", bias_initializer=\"zeros\"):\n",
    "  M = keras.Sequential()\n",
    "  M.add(keras.Input(shape=(784,)))\n",
    "  M.add(keras.layers.Dense(units=800, activation='relu',\n",
    "    kernel_initializer=kernel_initializer, bias_initializer=bias_initializer))\n",
    "  M.add(keras.layers.Dense(10, activation='softmax',\n",
    "    kernel_initializer=kernel_initializer, bias_initializer=bias_initializer))\n",
    "  opt = keras.optimizers.Adam(learning_rate=0.00015)\n",
    "  M.compile(loss=\"categorical_crossentropy\", optimizer=opt, metrics=[\"accuracy\"])\n",
    "  reduce_cb = keras.callbacks.ReduceLROnPlateau(\n",
    "    monitor='val_accuracy', factor=0.32, patience=5, restore_best_weights=True)\n",
    "  early_cb = keras.callbacks.EarlyStopping(monitor='val_accuracy', patience=10, min_delta=1e-5)\n",
    "  M.fit(x_train, y_train, batch_size=256, epochs=100, verbose=0, validation_data=(x_val, y_val),\n",
    "    callbacks=[reduce_cb, early_cb])\n",
    "  _, acc = M.evaluate(x_test, y_test, verbose=0)\n",
    "  return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precisión media: 89.50%  Desviación estándar: 0.07%\n",
      "Tiempo (hh:mm:ss): 00:01:24\n"
     ]
    }
   ],
   "source": [
    "import time; start = time.time()\n",
    "keras.utils.set_random_seed(seed=23); num_exp = 3; acc = np.zeros(num_exp)\n",
    "for exp in range(num_exp):\n",
    "    acc[exp] = run_exp()\n",
    "print(f'Precisión media: {acc.mean():.2%}  Desviación estándar: {acc.std():.2%}')\n",
    "print('Tiempo (hh:mm:ss):', time.strftime('%H:%M:%S', time.gmtime(time.time() - start)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Examen A3: ejercicio con CIFAR-10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En las dos primeras sesiones de laboratorio del bloque 2 seguimos con MNIST y Fashion-MNIST; vimos que con CNNs sencillas convenientemente regularizadas se obtenían precisiones en test muy buenas, del $\\,99.5\\%\\,$ en MNIST y $\\,92.0\\%\\,$ en Fashion-MNIST. A partir de la tercera sesión de laboratorio del bloque 2 utilizamos el corpus de imágenes a color CIFAR-10. El siguiente código lee CIFAR-10 con su partición train-test estándar y establece una partición train-val-test mediante partición del train estándar en train-val."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(40000, 32, 32, 3) (40000, 10) (10000, 32, 32, 3) (10000, 10) (10000, 32, 32, 3) (10000, 10)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np; import matplotlib.pyplot as plt\n",
    "import os; os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n",
    "import keras; from keras import layers\n",
    "keras.utils.set_random_seed(23)\n",
    "(x_train_val, y_train_val), (x_test, y_test) = keras.datasets.cifar10.load_data()\n",
    "x_train_val = x_train_val.astype(\"float32\")\n",
    "x_test = x_test.astype(\"float32\")\n",
    "y_train_val = keras.utils.to_categorical(y_train_val, 10)\n",
    "y_test = keras.utils.to_categorical(y_test, 10)\n",
    "x_train = x_train_val[:-10000]; x_val = x_train_val[-10000:]\n",
    "y_train = y_train_val[:-10000]; y_val = y_train_val[-10000:]\n",
    "print(x_train.shape, y_train.shape, x_val.shape, y_val.shape, x_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En la tercera sesión del bloque 2 (sesión 8) vimos que una CNN sencilla obtenía precisiones alrededor del $73\\%$. A continuación se define una función para realizar un experimento con dicha CNN sencilla. La normalización de imágenes, a $\\,[-1, 1],\\,$ se integra como primera capa tras la de entrada. Tras la normalización, la red aplica dos capas convolucionales de 32 y 64 filtros $\\,3\\times 3$. Cada capa convolucional viene seguida por una capa de agrupación MaxPooling con ventana $2\\times 2.$ Tras los dos pares Conv2D-MaxPooling2D, la salida se aplana y se procesa mediante un MLP como el del examen A1, si bien en este caso se añade una capa de regularización Dropout con probabilidad $\\,0.5\\,$ tras la capa oculta de $\\,800\\,$ unidades."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_exp2():\n",
    "  M = keras.Sequential()\n",
    "  M.add(keras.Input(shape=(32, 32, 3)))\n",
    "  M.add(layers.Rescaling(scale=1 / 127.5, offset=-1))\n",
    "  M.add(layers.Conv2D(32, kernel_size=(3, 3), activation=\"relu\"))\n",
    "  M.add(layers.MaxPooling2D(pool_size=(2, 2)))\n",
    "  M.add(layers.Conv2D(64, kernel_size=(3, 3), activation=\"relu\"))\n",
    "  M.add(layers.MaxPooling2D(pool_size=(2, 2)))\n",
    "  M.add(layers.Flatten())\n",
    "  M.add(layers.Dense(units=800, activation='relu'))\n",
    "  M.add(layers.Dropout(0.5))\n",
    "  M.add(layers.Dense(10, activation='softmax'))\n",
    "  opt = keras.optimizers.Adam(learning_rate=0.00015)\n",
    "  M.compile(loss=\"categorical_crossentropy\", optimizer=opt, metrics=[\"accuracy\"])\n",
    "  reduce_cb = keras.callbacks.ReduceLROnPlateau(\n",
    "    monitor='val_accuracy', factor=0.32, patience=5, restore_best_weights=True)\n",
    "  early_cb = keras.callbacks.EarlyStopping(monitor='val_accuracy', patience=10, min_delta=1e-5)\n",
    "  M.fit(x_train, y_train, batch_size=256, epochs=100, verbose=1, validation_data=(x_val, y_val),\n",
    "    callbacks=[reduce_cb, early_cb])\n",
    "  _, acc = M.evaluate(x_test, y_test, verbose=0)\n",
    "  return acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Repetimos `run_exp2` para comprobar que la CNN sencilla obtiene una precisión próxima al $73\\%$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precisión media: 73.02% Desviación estándar: 0.13%\n",
      "Tiempo (hh:mm:ss): 00:06:43\n"
     ]
    }
   ],
   "source": [
    "import time; start = time.time()\n",
    "keras.utils.set_random_seed(seed=23); num_exp = 3; acc = np.zeros(num_exp)\n",
    "for exp in range(num_exp):\n",
    "    acc[exp] = run_exp2()\n",
    "print(f'Precisión media: {acc.mean():.2%} Desviación estándar: {acc.std():.2%}')\n",
    "print('Tiempo (hh:mm:ss):', time.strftime('%H:%M:%S', time.gmtime(time.time() - start)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tras realizar un experimento similar al anterior, en las sesiones tercera y cuarta del bloque 2 nos centramos en el uso de redes pre-entrenadas con el fin de obtener precisiones por encima del $\\,90\\%\\,$ en CIFAR-10. Concretamente, hicimos uso de una ResNet50V2 descabezada para aprender, mediante transfer learning y fine-tuning, redes que superaban el $\\,95\\%$. Además, en línea con tendencias populares de los últimos años, conseguimos aumentar ligeramente las precisiones alcanzadas haciendo uso de aumento de datos. Por simplicidad, en este examen no haremos uso de redes pre-entrenadas, pero sí consideraremos la posibilidad de mejorar una CNN sencilla con aumento de datos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Ejercicio (2 puntos):** $\\;$ Define una nueva función `run_exp3` para experimentar con la CNN sencilla y aumento de datos. La API de las capas básicas de aumento de imágenes está en [https://keras.io/api/layers/preprocessing_layers](https://keras.io/api/layers/preprocessing_layers). En las sesiones de laboratorio ya hemos utilizado `RandomFlip` y `RandomTranslation`. Escoge las capas de aumento de imágenes que consideres prometedoras y aplícalas adecuadamente. Repite `run_exp3` al menos dos veces para estimar la precisión de la CNN sencilla con el aumento de datos definido; deberías obtener un $75\\%$ al menos. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-11 18:49:18.403303: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1733939358.457242  854554 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1733939358.471055  854554 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(40000, 32, 32, 3) (40000, 10) (10000, 32, 32, 3) (10000, 10) (10000, 32, 32, 3) (10000, 10)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np; import matplotlib.pyplot as plt\n",
    "import os; os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n",
    "import keras; from keras import layers\n",
    "keras.utils.set_random_seed(23)\n",
    "(x_train_val, y_train_val), (x_test, y_test) = keras.datasets.cifar10.load_data()\n",
    "x_train_val = x_train_val.astype(\"float32\")\n",
    "x_test = x_test.astype(\"float32\")\n",
    "y_train_val = keras.utils.to_categorical(y_train_val, 10)\n",
    "y_test = keras.utils.to_categorical(y_test, 10)\n",
    "x_train = x_train_val[:-10000]; x_val = x_train_val[-10000:]\n",
    "y_train = y_train_val[:-10000]; y_val = y_train_val[-10000:]\n",
    "print(x_train.shape, y_train.shape, x_val.shape, y_val.shape, x_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_exp3():\n",
    "  M = keras.Sequential()\n",
    "  M.add(keras.Input(shape=(32, 32, 3)))\n",
    "  M.add(layers.Rescaling(scale=1 / 127.5, offset=-1))\n",
    "  M.add(layers.RandomFlip(\"horizontal\"))\n",
    "  # M.add(layers.RandomTranslation(0.2, 0.2, fill_mode=\"nearest\"))\n",
    "  M.add(layers.Conv2D(32, kernel_size=(3, 3), activation=\"relu\"))\n",
    "  M.add(layers.MaxPooling2D(pool_size=(2, 2)))\n",
    "  M.add(layers.Conv2D(64, kernel_size=(3, 3), activation=\"relu\"))\n",
    "  M.add(layers.MaxPooling2D(pool_size=(2, 2)))\n",
    "  M.add(layers.Flatten())\n",
    "  M.add(layers.Dense(units=800, activation='relu'))\n",
    "  M.add(layers.Dropout(0.5))\n",
    "  M.add(layers.Dense(10, activation='softmax'))\n",
    "  opt = keras.optimizers.Adam(learning_rate=0.00015)\n",
    "  M.compile(loss=\"categorical_crossentropy\", optimizer=opt, metrics=[\"accuracy\"])\n",
    "  reduce_cb = keras.callbacks.ReduceLROnPlateau(\n",
    "    monitor='val_accuracy', factor=0.32, patience=5, restore_best_weights=True)\n",
    "  early_cb = keras.callbacks.EarlyStopping(monitor='val_accuracy', patience=10, min_delta=1e-5)\n",
    "  M.fit(x_train, y_train, batch_size=256, epochs=100, verbose=0, validation_data=(x_val, y_val),\n",
    "    callbacks=[reduce_cb, early_cb])\n",
    "  _, acc = M.evaluate(x_test, y_test, verbose=0)\n",
    "  return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1733939366.321116  854554 gpu_device.cc:2022] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 2616 MB memory:  -> device: 0, name: NVIDIA GeForce GTX 1650, pci bus id: 0000:01:00.0, compute capability: 7.5\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1733939368.223517  875960 service.cc:148] XLA service 0x7f074400b350 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "I0000 00:00:1733939368.223548  875960 service.cc:156]   StreamExecutor device (0): NVIDIA GeForce GTX 1650, Compute Capability 7.5\n",
      "I0000 00:00:1733939368.356017  875960 cuda_dnn.cc:529] Loaded cuDNN version 90300\n",
      "I0000 00:00:1733939370.567196  875960 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precisión media: 75.89% Desviación estándar: 0.08%\n",
      "Tiempo (hh:mm:ss): 00:05:08\n"
     ]
    }
   ],
   "source": [
    "import time; start = time.time()\n",
    "keras.utils.set_random_seed(seed=23); num_exp = 2; acc = np.zeros(num_exp)\n",
    "for exp in range(num_exp):\n",
    "    acc[exp] = run_exp3()\n",
    "print(f'Precisión media: {acc.mean():.2%} Desviación estándar: {acc.std():.2%}')\n",
    "print('Tiempo (hh:mm:ss):', time.strftime('%H:%M:%S', time.gmtime(time.time() - start)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "per",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
