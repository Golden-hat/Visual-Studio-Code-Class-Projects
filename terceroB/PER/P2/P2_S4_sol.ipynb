{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "58B27Xk_RkUS"
      },
      "source": [
        "# KVecinos en un dataset de detección de spam\n",
        "\n",
        "Se propone emplear un clasificador basado en distancias sobre el dataset id=44 de openml de detección de Spam. Son un total de 4601 muestras con 57 características."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "ol4-XMphRR0o"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(4601, 57)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/yassin/anaconda3/envs/per/lib/python3.11/site-packages/sklearn/datasets/_openml.py:968: FutureWarning: The default value of `parser` will change from `'liac-arff'` to `'auto'` in 1.4. You can set `parser='auto'` to silence this warning. Therefore, an `ImportError` will be raised from 1.4 if the dataset is dense and pandas is not installed. Note that the pandas parser may return different data types. See the Notes Section in fetch_openml's API doc for details.\n",
            "  warn(\n"
          ]
        }
      ],
      "source": [
        "from sklearn.datasets import fetch_openml\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "## Descarga del dataset Spam\n",
        "X, y = fetch_openml(data_id=44, as_frame=False, cache=True, return_X_y=True)\n",
        "print(X.shape)\n",
        "\n",
        "## Partición train/test\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, shuffle=True, random_state=23)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ylTk-2JuSJyD"
      },
      "source": [
        "## El clasificador por los vecinos más cercanos"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9fwMFShNRfKk",
        "outputId": "c0c027af-78f8-4f85-c551-68ff804cda2e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Precisión: 79.5%\n"
          ]
        }
      ],
      "source": [
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "\n",
        "kv = KNeighborsClassifier()\n",
        "acc=kv.fit(X_train,y_train).score(X_test,y_test)\n",
        "\n",
        "print(f'Precisión: {acc:.1%}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IMCCldnbSR9g"
      },
      "source": [
        "**Ejercicio:** Explora el principal parámetros del KNN (n_neighbors) y realiza una búsqueda mediante alguna técnica de optimización ya vista en la práctica anterior"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QxptkGJ9SQ8f",
        "outputId": "8d20d012-c2f2-41cf-b1f9-314ff497891d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Precisión: 82.1% con {'n_neighbors': 1}\n"
          ]
        }
      ],
      "source": [
        "# Solución\n",
        "\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "G = {\"n_neighbors\":[1,3,4,5,10]}\n",
        "\n",
        "GS = GridSearchCV(KNeighborsClassifier(), G, scoring='accuracy', refit=True, cv=5)\n",
        "\n",
        "acc = GS.fit(X_train, y_train).score(X_test, y_test)\n",
        "print(f'Precisión: {acc:.1%} con {GS.best_params_}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pUGR1U0CTSyV"
      },
      "source": [
        "## Mejoras\n",
        "\n",
        "La función de distancia empleada por defecto es la distancia euclídea. Dicha distancia requiere un preproceso de las muestras para que tengan una escala similar todas ellas. Además KNN podría beneficiarse de una proyección mediante PCA con el fin de reducir la dimensionalidad.\n",
        "\n",
        "**Ejercicio:** Implementa un pipeline con la normalización de los datos y un PCA, seguido del KNN. Busca los mejores parámetros. Se podría conseguir una tasa de acierto >90%.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iff6iyN-Tw4G",
        "outputId": "c627d453-ccb7-4486-e5f0-785b120fc93b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Precisión: 90.8% con {'knn__n_neighbors': 3, 'pca__n_components': 20}\n"
          ]
        }
      ],
      "source": [
        "# Solución\n",
        "\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.pipeline import Pipeline;\n",
        "\n",
        "scaler = StandardScaler()\n",
        "pca = PCA()\n",
        "knn = KNeighborsClassifier()\n",
        "\n",
        "pipe = Pipeline(steps=[(\"scaler\", scaler), (\"pca\", pca), (\"knn\", knn)])\n",
        "\n",
        "G = {\"pca__n_components\": [5,10,15,20,25,50], \"knn__n_neighbors\": [1,3,4,5]}\n",
        "GS = GridSearchCV(pipe, G, scoring='accuracy', refit=True, cv=5)\n",
        "acc = GS.fit(X_train, y_train).score(X_test, y_test)\n",
        "print(f'Precisión: {acc:.1%} con {GS.best_params_}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w8r-aW7yWMru"
      },
      "source": [
        "También podríamos probar diferentes funciones de distancia [sklearn distances](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.pairwise.distance_metrics.html#sklearn.metrics.pairwise.distance_metrics) a emplear en el parámetro \"metric\". Así mismo podríamos explorar el parámetro \"weights\" que pondera el voto de cada vecino de forma diferente según el parámetro escogido.\n",
        "\n",
        "**Ejercicio:** prueba también diferentes métricas y \"weights\" junto con todo lo anterior. Emplea el BayessianOpt visto en la práctica anterior."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IjHbn79eVfHK",
        "outputId": "ea1a18e9-1e37-4f15-8075-29eff4a77803"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: scikit-optimize in /home/yassin/anaconda3/envs/per/lib/python3.11/site-packages (0.10.1)\n",
            "Requirement already satisfied: joblib>=0.11 in /home/yassin/anaconda3/envs/per/lib/python3.11/site-packages (from scikit-optimize) (1.4.2)\n",
            "Requirement already satisfied: pyaml>=16.9 in /home/yassin/anaconda3/envs/per/lib/python3.11/site-packages (from scikit-optimize) (24.4.0)\n",
            "Requirement already satisfied: numpy>=1.20.3 in /home/yassin/anaconda3/envs/per/lib/python3.11/site-packages (from scikit-optimize) (1.26.4)\n",
            "Requirement already satisfied: scipy>=1.1.0 in /home/yassin/anaconda3/envs/per/lib/python3.11/site-packages (from scikit-optimize) (1.13.1)\n",
            "Requirement already satisfied: scikit-learn>=1.0.0 in /home/yassin/anaconda3/envs/per/lib/python3.11/site-packages (from scikit-optimize) (1.5.0)\n",
            "Requirement already satisfied: packaging>=21.3 in /home/yassin/anaconda3/envs/per/lib/python3.11/site-packages (from scikit-optimize) (24.0)\n",
            "Requirement already satisfied: PyYAML in /home/yassin/anaconda3/envs/per/lib/python3.11/site-packages (from pyaml>=16.9->scikit-optimize) (6.0.1)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /home/yassin/anaconda3/envs/per/lib/python3.11/site-packages (from scikit-learn>=1.0.0->scikit-optimize) (3.5.0)\n"
          ]
        }
      ],
      "source": [
        "# Solución\n",
        "!pip install scikit-optimize\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aqG3GHMuVM7r",
        "outputId": "3b2473b7-16ef-4e24-a648-b6f11c5ebe11"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Precisión: 92.4% con OrderedDict([('knn__metric', 'l2'), ('knn__n_neighbors', 14), ('knn__weights', 'distance'), ('pca__n_components', 17)])\n"
          ]
        }
      ],
      "source": [
        "# Solución\n",
        "from skopt import BayesSearchCV\n",
        "from skopt.space import Real, Categorical, Integer\n",
        "from sklearn.datasets import fetch_openml\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.discriminant_analysis import StandardScaler\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV;\n",
        "from sklearn.decomposition import PCA;\n",
        "from sklearn.pipeline import Pipeline;\n",
        "from skopt import BayesSearchCV;\n",
        "\n",
        "\n",
        "# Probar sólo 10 combinaciones de parámetros, n_iter=10\n",
        "scaler = StandardScaler()\n",
        "pca = PCA()\n",
        "knn = KNeighborsClassifier()\n",
        "\n",
        "pipe = Pipeline(steps=[(\"scaler\", scaler), (\"pca\", pca), (\"knn\", knn)])\n",
        "\n",
        "G = {\"pca__n_components\": Integer(1,57),\n",
        "     \"knn__n_neighbors\": Integer(1,20),\n",
        "     \"knn__metric\": Categorical([\"l1\",\"l2\"]),\n",
        "     \"knn__weights\":Categorical([\"uniform\",\"distance\"])}\n",
        "\n",
        "BS = BayesSearchCV(pipe, G, scoring='accuracy', n_iter=20, refit=True, cv=5)\n",
        "\n",
        "acc = BS.fit(X_train, y_train).score(X_test, y_test)\n",
        "print(f'Precisión: {acc:.1%} con {BS.best_params_}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eCSmzF9XZXE2"
      },
      "source": [
        "## Olivetti Faces\n",
        "\n",
        "Prueba ahora el clasificador KNN junto con todos los parámetros y preprocesos que creas convenientes sobre el dataset de reconocimiento facial de Olivetti."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TFASY_RGZheI",
        "outputId": "b5ae5c29-48ac-4e25-b843-6167bb30ba16"
      },
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'fetch_olivetti_faces' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[1], line 13\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpipeline\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Pipeline;\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mskopt\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m BayesSearchCV;\n\u001b[0;32m---> 13\u001b[0m X, y \u001b[38;5;241m=\u001b[39m \u001b[43mfetch_olivetti_faces\u001b[49m(return_X_y\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m     14\u001b[0m X_train, X_test, y_train, y_test \u001b[38;5;241m=\u001b[39m train_test_split(X, y, test_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.2\u001b[39m, shuffle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m23\u001b[39m)\n\u001b[1;32m     17\u001b[0m \u001b[38;5;66;03m# Probar sólo 10 combinaciones de parámetros, n_iter=10\u001b[39;00m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'fetch_olivetti_faces' is not defined"
          ]
        }
      ],
      "source": [
        "# Solución\n",
        "from skopt import BayesSearchCV\n",
        "from skopt.space import Real, Categorical, Integer\n",
        "from sklearn.datasets import fetch_olivetti_faces\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.discriminant_analysis import StandardScaler\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV;\n",
        "from sklearn.decomposition import PCA;\n",
        "from sklearn.pipeline import Pipeline;\n",
        "from skopt import BayesSearchCV;\n",
        "\n",
        "X, y = fetch_olivetti_faces(return_X_y=True)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, shuffle=True, random_state=23)\n",
        "\n",
        "\n",
        "# Probar sólo 10 combinaciones de parámetros, n_iter=10\n",
        "scaler = StandardScaler()\n",
        "pca = PCA()\n",
        "knn = KNeighborsClassifier()\n",
        "\n",
        "pipe = Pipeline(steps=[(\"scaler\", scaler), (\"pca\", pca), (\"knn\", knn)])\n",
        "\n",
        "G = {\"pca__n_components\": Integer(10,200),\n",
        "     \"knn__n_neighbors\": Integer(1,10),\n",
        "     \"knn__metric\": Categorical([\"l1\",\"l2\"]),\n",
        "     \"knn__weights\":Categorical([\"uniform\",\"distance\"])}\n",
        "\n",
        "BS = BayesSearchCV(pipe, G, scoring='accuracy', n_iter=20, refit=True, cv=5,verbose=10)\n",
        "\n",
        "acc = BS.fit(X_train, y_train).score(X_test, y_test)\n",
        "print(f'Precisión: {acc:.1%} con {BS.best_params_}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
