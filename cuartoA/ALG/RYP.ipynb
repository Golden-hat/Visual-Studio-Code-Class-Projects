{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## _Introducción_\n",
    "\n",
    "Se tratan de un problema de optimización que, por regla general, no tiene un algoritmo eficiente. Se basa en una exploración del árbol de soluciones similar a **backtracking** solo que en profundidad y con una **poda** de estados por factibilidad. Esto se hace en un contexto donde:\n",
    "- Hay más de un estado activo.\n",
    "- Hay un criterio de selección diferente.\n",
    "- Hay criterios de poda adicionales.\n",
    "\n",
    "En el proceso de ramificación y poda se llevan a cabo las siguientes acciones:\n",
    "- Selección:\n",
    "  - En cada instante hay una serie de estados no visitados a los que denominamos **\"estados activos\"**, y se debe escoger uno para explorar. Seleccionaremos siempre el **más prometedor**, lo que nos asegura alcanzar la solución óptima al problema lo antes posible.\n",
    "- Ramificación: Se basa en expandir el estado activo actual en nodos hijos con configuraciones heredadas del nodo padre, \"completando\" la solución.\n",
    "- Poda:\n",
    "  - Consideramos tanto la poda por factibilidad como la poda por **cota optimsta**. Una función estima el valor de la función objetivo sobre la mejor solución de un estado, produciendo **siempre un valor igual que este**. Si el valor de este estado es peor que el visto hasta el momento, se poda.\n",
    "  \n",
    "**_Ejemplo con mochila discreta_**\n",
    "\n",
    "Es una variante más del ya conocido problema de la mochila.\n",
    "\n",
    "Lo modelamos tal que:\n",
    "\n",
    "$ W = 10, w=[12,5,6,2,6], v=[10,2,3,4,2]$\n",
    "\n",
    "$\\text{Soluciones:} \\ (0,1,0,0,0), (0,0,1,1,0), (0,0,0,0,0)... $\n",
    "\n",
    "De manera que podemos definir el espacio de soluciones tal que...\n",
    "\n",
    "$ X = \\{(x_1, x_2, ..., x_N) \\in {0, 1^N} | \\sum_{1 \\leq i \\leq N}{x_iw_i} \\leq W \\}$\n",
    "\n",
    "La función objetivo sería...\n",
    "\n",
    "$ f((x_1, x_2, ..., x_N)) = \\sum_{1 \\leq i \\leq N}{x_iv_i} $\n",
    "\n",
    "De la cual buscaríamos los argumentos que maximizaran su resultado\n",
    "\n",
    "$ \\argmax_{(x_1, x_2, ..., x_N)\\in X} \\sum_{ \\leq i \\leq N}{x_iv_i}$ \n",
    "\n",
    "#### Esto ya lo sabemos de ejercicios anteriores. Sin embargo, ahora presentamos el concepto de **estado**.\n",
    "\n",
    "- Estado inicial $ \\rightarrow (?) = X $\n",
    "- Estado intermedio:\n",
    "  - Estado que representa un conjunto de soluciones **factibles o no**. Puede ser:\n",
    "    - **Prometedor**, estado que _podría_ contener la solución factible buscada.\n",
    "    - **No factible**, estado que seguro que no contiene ninguna solución factible.\n",
    "- Estado unitario o terminal:\n",
    "  - Contiene una solución al problema (que puede ser cualquiera y no necesariamente la mejor).\n",
    "\n",
    "A partir del estado inicial ramificaremos subconjuntos de soluciones y seguiremos la expansión por aquellos que sean **prometedores**.\n",
    "En cada iteración...\n",
    "- Seleccionamos un estado activo y lo extraemos de A.\n",
    "- Ramificamos e insertamos en A los hijos.\n",
    "- Eliminar de A los hijos no prometedores.\n",
    "\n",
    "Donde A es un subset que contiene los estados que podrían derivar a la solución factible.\n",
    "\n",
    "Así pues, con un problema tal que...\n",
    "\n",
    "$ W = 10, w=[12,5,6,2,6], v=[10,2,3,4,2]$\n",
    "\n",
    "<center>\n",
    "<img src=./resources/mochilaarbol.png alt=\"image\">\n",
    "</center>\n",
    "\n",
    "No hemos llegado a esa solución por mera coincidencia, hemos hecho un **cribado** seleccionando siempre los valores más prometedores a expandir. **Aunque hemos necesitado comprobar más de la cuenta ya que nada nos aseguraba la solución óptima** Tanto es así, que hemos tenido que vaciar por completo el conjunto de hijos prometedores A.\n",
    "\n",
    "<center>\n",
    "<img src=./resources/mochilaexpandido.png alt=\"image\">\n",
    "</center>\n",
    "\n",
    "**Puntuación basada en una estimación**\n",
    "\n",
    "Es una buena manera de explorar menos en el árbol el guiarnos por\n",
    "- Valor de los objetos sobre los que hemos decidido su inclusión.\n",
    "- Valor de los objetos sobre los que aún no hemos decidido nada.\n",
    "\n",
    "De tal manera, es siempre conveniente:\n",
    "- **Relajar las restricciones del problema.**\n",
    "- **Resolver un problema relajado proporciona una estimación optimista de lo que obtendré con el problema original.**\n",
    "\n",
    "##### Como por ejemplo en el siguiente ejemplo donde nos \"guiamos\" seleccionando el nodo cuyo valores restantes sumen un mayor valor\n",
    "\n",
    "Huelga decir que todos aquellos estados que incumplan las reglas de una solución posible **no aparecen representados**, es decir, toda combinación de objetos que no quepa en la mochila no será representada en el árbol.\n",
    "\n",
    "<center>\n",
    "<img src=./resources/drawntree.png alt=\"image\">\n",
    "</center>\n",
    "\n",
    "Esta vez no hemos tenido que explorar tantos estados. **Gracias a que los estados se puntúan con una estimación optimista hemos podido acceder rápidamente a la solución, ya que los estados que \"prometían\" no lo hacían tanto en comparación con la solución encontrada**\n",
    "\n",
    "<center>\n",
    "<img src=./resources/drawtreeclean.png alt=\"image\">\n",
    "</center>\n",
    "\n",
    "## _Esquema de ramificación y poda_\n",
    "\n",
    "Existe un esquema de referencia para llevar a cabo los ejercicios y los problemas de ramificación y poda. Este esquema usa una **estimación optimista con poda implícita**.\n",
    "\n",
    "La poda implícita es un concepto relacionado con los algoritmos de branch and bound, y se refiere a la eliminación de ramas del espacio de búsqueda sin necesidad de explorarlas completamente. A diferencia de la poda explícita, que ocurre cuando se toma una decisión consciente de no explorar una rama en particular (basada en una regla o cota explícita), la poda implícita se da de forma \"automática\" o implícita a medida que el algoritmo sigue sus reglas de optimización.\n",
    "\n",
    "**Diferencia con la poda explícita**\n",
    "\n",
    "- _Poda explícita_: En algunos casos, el algoritmo puede tener una regla específica para descartar una rama. Por ejemplo, si se sabe que una rama nunca podrá proporcionar una solución válida o factible, se puede decidir explícitamente no explorarla.\n",
    "\n",
    "- _Poda implícita_: En este caso, el algoritmo toma una decisión implícita de no explorar una rama, basándose en una comparación de cotas o evaluaciones que indican que la rama no llevará a una mejor solución. Esto no requiere una acción explícita de descartar la rama.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BranchAndBoundScheme:\n",
    "    def is_complete(self, s):\n",
    "        \"\"\"Determines if a state is complete.\"\"\"\n",
    "        # Implement logic to check if the state s represents a complete solution.\n",
    "        pass\n",
    "\n",
    "    def is_factible(self, s):\n",
    "        \"\"\"Determines if a state is feasible.\"\"\"\n",
    "        # Implement logic to check if the state s is a feasible solution.\n",
    "        pass\n",
    "\n",
    "    def worst_value(self):\n",
    "        \"\"\"Returns the worst possible value (used as an initial comparison for optimization).\"\"\"\n",
    "        # Return the worst possible value for the objective function.\n",
    "        pass\n",
    "\n",
    "    def branch(self, s):\n",
    "        \"\"\"Generates the next possible states (branches) from a given state.\"\"\"\n",
    "        # Implement logic to generate branches (next possible states) from the current state s.\n",
    "        pass\n",
    "\n",
    "    def f(self, s):\n",
    "        \"\"\"Objective function for a state.\"\"\"\n",
    "        # Implement the objective function f(s) which evaluates the state s.\n",
    "        pass\n",
    "\n",
    "    def opt(self, a, b):\n",
    "        \"\"\"Optimization function to compare two values.\"\"\"\n",
    "        # Implement the optimization function that compares two values a and b, \n",
    "        # returning the better value according to the problem's objective.\n",
    "        pass\n",
    "\n",
    "    def optimistic_bound(self, s):\n",
    "        \"\"\"Calculates the optimistic bound of the objective value for state s.\"\"\"\n",
    "        # Implement logic to calculate the optimistic bound on the value of the objective function \n",
    "        # for the state s, considering potential future developments.\n",
    "        pass\n",
    "\n",
    "    def priority_queue(self, iterable=[]):\n",
    "        \"\"\"Creates a priority queue from the given iterable.\"\"\"\n",
    "        # Implement a priority queue structure to handle states based on their optimistic bounds.\n",
    "        # You can use a heap-based priority queue or any appropriate implementation.\n",
    "        pass\n",
    "\n",
    "    def solve(self, initial_state):\n",
    "        \"\"\"Solves the optimization problem using branch and bound.\"\"\"\n",
    "        \n",
    "        # Check if the initial state is complete and return it if true\n",
    "        if self.is_complete(self.X):\n",
    "            return self.X\n",
    "        \n",
    "        # Initialize the priority queue with the initial state and its optimistic bound\n",
    "        A = self.priority_queue([self.optimistic_bound(self.X), self.X])\n",
    "        x, fx = None, self.worst_value()  # Initialize the best solution (x) and its score (fx)\n",
    "       \n",
    "        # Loop until the priority queue is empty. The second condition ensures the implicit prune.\n",
    "        while len(A) != 0 and self.opt(A.opt()[0], fx) != fx:\n",
    "            # Extract the state with the best optimistic bound from the priority queue\n",
    "            (score_s, s) = A.extract_opt()\n",
    "            \n",
    "            # Generate all branches from the current state\n",
    "            for score in self.branch(s):\n",
    "                if self.is_complete(score):\n",
    "                    # If the state is complete, check if it's feasible and better than the current best solution\n",
    "                    if self.is_factible(score) and self.opt(fx, self.f(score)) != fx:\n",
    "                        x, fx = score, self.f(score)\n",
    "                else:\n",
    "                    # Calculate the optimistic bound for the branch\n",
    "                    optimistic_score = self.optimistic_bound(score)\n",
    "                    \n",
    "                    # Only add the branch to the priority queue if it could potentially lead to a better solution\n",
    "                    if self.opt(optimistic_score, fx) != fx:\n",
    "                        A.insert((optimistic_score, score))\n",
    "        \n",
    "        # Return the best solution found\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## _Construcción y consejos sobre cotas optimistas_\n",
    "\n",
    "Es bueno considerar que un estado representa soluciones de las que ya conozco una parte... y nada sé de la otra parte. La función optimista puede estructurarse en 2 partes:\n",
    "\n",
    "$ \\text{optimistic} \\left((s_1, s_2, s_3, ..., s_k, ?)\\right)$\n",
    "\n",
    "- Parte conocida:   $ \\ \\sum_{1 \\leq i \\leq k}{s_iv_i}$\n",
    "- Parte desconocida:  $ \\ \\sum_{k \\leq i \\leq N}{v_i} $\n",
    "\n",
    "$ \\text{optimistic} \\left((s_1, s_2, s_3, ..., s_k, ?)\\right) = \\sum_{1 \\leq i \\leq k}{s_iv_i} + \\sum_{k \\leq i \\leq N}{v_i} $\n",
    "\n",
    "La parte desconocida puede verse como una instancia nueva del mismo problema, pero de menor talla. Calculando el valor exacto de la parte conocida, le **añadimos una estimación optimista de la parte desconocida**, con lo que se obitene una estimación optimista GLOBAL. (Como se ha hecho anteriormente).\n",
    "\n",
    "Es importante elegir la cota atendiendo a los siguientes criterios:\n",
    "- Calidad de la aproximación.\n",
    "- Costes espaciales y temporales del cálculo.\n",
    "\n",
    "\n",
    "#### Construcción de cotas incrementales\n",
    "\n",
    "El cálculo de una cota incremental se hace teniendo en cuenta el valor de la cota previa (padre). Tomando como ejemplo el problema de la mochila, la cota incremental para el valor de los nodos hijo del nodo k sería...\n",
    "\n",
    "$ cota(x_1, x_2, ..., x_k, 1) = cota(x_1, x_2, ..., x_k)$\n",
    "\n",
    "$ cota(x_1, x_2, ..., x_k, 0) = cota(x_1, x_2, ..., x_k) - v_{k+1}$\n",
    "\n",
    "\n",
    "## _Variantes del esquema originial_\n",
    "\n",
    "Hay 4 líneas de mejora por lo general:\n",
    "\n",
    "### Poda temprana\n",
    "\n",
    "El esquema no poda hasta encontrar una solución completa... Pero y si me invento una al principio? Este algoritmo pretende encontrar una solución para poder podar cuanto antes. Lo ideal es que esta solución esté cerca de la solución óptima, para hacer el proceso más efectivo.\n",
    "\n",
    "Este esquema presenta las siguientes modificaciones con respecto al original:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BranchAndBoundWithInitializationScheme(BranchAndBoundScheme):   \n",
    "  \"\"\"\"\n",
    "  DIFERENCIA CON LA CLASE ANTERIOR\n",
    "  Se añade el método arbitrary_solution \n",
    "  \"\"\"\n",
    "  def arbitrary_solution(self):\n",
    "    \"\"\"Proporciona un elemento arbitrario de X, o sea, un elemento cualquiera de X.\"\"\"\n",
    "    \n",
    "  def solve(self, initial_state):\n",
    "      \"\"\"Solves the optimization problem using branch and bound.\"\"\"\n",
    "      \n",
    "      # Check if the initial state is complete and return it if true\n",
    "      if self.is_complete(self.X):\n",
    "          return self.X\n",
    "      \n",
    "      # Initialize the priority queue with the initial state and its optimistic bound\n",
    "      A = self.priority_queue([self.optimistic_bound(self.X), self.X])\n",
    "\n",
    "      \"\"\"\"\n",
    "      DIFERENCIA CON LA CLASE ANTERIOR\n",
    "      x, fx = None, self.worst_value() se sustituye por...\n",
    "      \"\"\"\n",
    "      x, fx = self.arbitrary_solution, self.f()  # Initialize the best solution (x) and its score (fx)\n",
    "      \n",
    "      # Loop until the priority queue is empty. The second condition ensures the implicit prune.\n",
    "      while len(A) != 0 and self.opt(A.opt()[0], fx) != fx:\n",
    "          # Extract the state with the best optimistic bound from the priority queue\n",
    "          (score_s, s) = A.extract_opt()\n",
    "          \n",
    "          # Generate all branches from the current state\n",
    "          for score in self.branch(s):\n",
    "              if self.is_complete(score):\n",
    "                  # If the state is complete, check if it's feasible and better than the current best solution\n",
    "                  if self.is_factible(score) and self.opt(fx, self.f(score)) != fx:\n",
    "                      x, fx = score, self.f(score)\n",
    "              else:\n",
    "                  # Calculate the optimistic bound for the branch\n",
    "                  optimistic_score = self.optimistic_bound(score)\n",
    "                  \n",
    "                  # Only add the branch to the priority queue if it could potentially lead to a better solution\n",
    "                  if self.opt(optimistic_score, fx) != fx:\n",
    "                      A.insert((optimistic_score, score))\n",
    "      \n",
    "      # Return the best solution found\n",
    "      return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cota pesimista\n",
    "\n",
    "Una cota es pesimista cuando las soluciones voraces o escogidas al azar son pesimistas y mediante estas me guio por el árbol para encontrar la solución factible. Siempre seleccionaremos la cota pesimista que **mayor provecho nos represente**\n",
    "\n",
    "Una cota es pesimista si...\n",
    "\n",
    "$ \\text{opt}(\\text{pessimistic}(s), opt_{x \\in s \\cap X }f(x)) = opt_{x \\in s \\cap X }f(x) $ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BranchAndBoundWithInitializationScheme(BranchAndBoundScheme):   \n",
    "  \"\"\"\"\n",
    "  DIFERENCIA CON LA CLASE ANTERIOR\n",
    "  Se añade el método pessimistic\n",
    "  \"\"\"\n",
    "  def pessimistic(self):\n",
    "    \"\"\"Proporciona un elemento arbitrario de X, o sea, un elemento cualquiera de X.\"\"\"\n",
    "    \n",
    "  def solve(self, initial_state):\n",
    "      \"\"\"Solves the optimization problem using branch and bound.\"\"\"\n",
    "      \n",
    "      # Check if the initial state is complete and return it if true\n",
    "      if self.is_complete(self.X):\n",
    "          return self.X\n",
    "      \n",
    "      # Initialize the priority queue with the initial state and its optimistic bound\n",
    "      A = self.priority_queue([self.optimistic_bound(self.X), self.X])\n",
    "\n",
    "      x, fx = None, self.worst_value()\n",
    "      \"\"\"\"\n",
    "      DIFERENCIA CON LA CLASE ANTERIOR\n",
    "      se instancia worst a la cota pesimista\n",
    "      \"\"\" \n",
    "      worst = self.pessimistic(self.X)\n",
    "      \n",
    "      # Loop until the priority queue is empty. The second condition ensures the implicit prune.\n",
    "      while len(A) != 0 and self.opt(A.opt()[0], fx) != fx:\n",
    "          # Extract the state with the best optimistic bound from the priority queue\n",
    "          (score_s, s) = A.extract_opt()\n",
    "          \n",
    "          # Generate all branches from the current state\n",
    "          for score in self.branch(s):\n",
    "              if self.is_complete(score):\n",
    "                  # If the state is complete, check if it's feasible and better than the current best solution\n",
    "                  if self.is_factible(score) and self.opt(fx, self.f(score)) != fx:\n",
    "                      x, fx = score, self.f(score)\n",
    "                      \"\"\"\"Diferencia\"\"\"\n",
    "                      worst = self.optimistic_bound(worst, fx)\n",
    "              else:\n",
    "                  # Calculate the optimistic bound for the branch\n",
    "                  optimistic_score = self.optimistic_bound(score)\n",
    "                  \n",
    "                  # Only add the branch to the priority queue if it could potentially lead to a better solution\n",
    "                  \"\"\"Diferencia\"\"\"\n",
    "                  if self.optimistic_bound(optimistic_score, worst) == optimistic_score and self.opt(optimistic_score, fx) != fx:\n",
    "                      A.insert((optimistic_score, score))\n",
    "      \n",
    "      # Return the best solution found\n",
    "      return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tolerancia\n",
    "\n",
    "Elegimos acelerar el algoritmo aproximándonos a una solución que entra dentro de unos márgenes de tolerancia aceptables, pero que **no representa una solución óptima al problema necesariamente**.\n",
    "\n",
    "Para ello necesitaremos una función de tolerancia $ \\ \\text{tolerance} (f(x))$\n",
    "Con ella, podremos podar estados que no cumplan que...\n",
    "\n",
    "$ \\text{optimistic}(s) \\leq f(x)$\n",
    "\n",
    "Donde x es la **mejor solución vista**.\n",
    "\n",
    "Ahora me lo cargaré si...\n",
    "\n",
    "$ \\text{optimistic}(s) \\leq f(x) + \\text{tolerance} (f(x)) $\n",
    "\n",
    "Haciendo eso llegaremos eventualmente a una solución $ x_0 $ tal que\n",
    "\n",
    "$ f(x_0) \\leq f(\\hat{x}) \\leq f(x_0) + \\text{tolerance} (f(x))$\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ApproximateBranchAndBoundScheme(BranchAndBoundScheme):\n",
    "  \"\"\"Diferencia. Se añade método tolerance\"\"\"\n",
    "  def tolerance(self, fx):\n",
    "    \"\"\"Tolerancia con la que una solución se considera aceptable.\"\"\"\n",
    "    \n",
    "  def solve(self, initial_state):\n",
    "    \"\"\"Solves the optimization problem using branch and bound.\"\"\"\n",
    "    \n",
    "    # Check if the initial state is complete and return it if true\n",
    "    if self.is_complete(self.X):\n",
    "        return self.X\n",
    "    \n",
    "    # Initialize the priority queue with the initial state and its optimistic bound\n",
    "    A = self.priority_queue([self.optimistic_bound(self.X), self.X])\n",
    "    x, fx, approx_fx = None, self.worst_value(), self.worst_value() # Initialize the best solution (x) and its score (fx)\n",
    "    \n",
    "    # Loop until the priority queue is empty. The second condition ensures the implicit prune.\n",
    "    \"\"\"Diferencia. Se cambia fx por approx_fx\"\"\"\n",
    "    while len(A) != 0 and self.opt(A.opt()[0], approx_fx) != approx_fx:\n",
    "        # Extract the state with the best optimistic bound from the priority queue\n",
    "        (score_s, s) = A.extract_opt()\n",
    "        \n",
    "        # Generate all branches from the current state\n",
    "        for score in self.branch(s):\n",
    "            if self.is_complete(score):\n",
    "                # If the state is complete, check if it's feasible and better than the current best solution\n",
    "                if self.is_factible(score) and self.opt(fx, self.f(score)) != fx:\n",
    "                    x, fx = score, self.f(score)\n",
    "                    approx_fx = fx + self.tolerance(fx)\n",
    "            else:\n",
    "                # Calculate the optimistic bound for the branch\n",
    "                optimistic_score = self.optimistic_bound(score)\n",
    "                \n",
    "                # Only add the branch to the priority queue if it could potentially lead to a better solution\n",
    "                if self.opt(optimistic_score, approx_fx) != approx_fx:\n",
    "                    A.insert((optimistic_score, score))\n",
    "    \n",
    "    # Return the best solution found\n",
    "    return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hibridación con programación dinámica\n",
    "\n",
    "No tiene sentido mantener 2 estados activos a la vez si son equivalentes, ya que cuando se completen lo harán con la misma \"mejor\" solución. Podemos aprovecharnos de la programación dinámica para cribar estos estados ya que una siempre ganará realmente sobre la otra opción. No veremos esta alternativa en detalle."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
